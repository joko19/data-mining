{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Praktikum Imbalanced Class"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, roc_curve, auc, f1_score, accuracy_score,confusion_matrix\n",
    "colnames =['preg','plas','pres','skin','test', 'mass', 'pedi','age','class']\n",
    "df=pd.read_csv('../resource/diabetes.csv',names=colnames)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>test</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>627.000</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>351.000</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>672.000</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>167.000</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preg  plas  pres  skin  test  mass     pedi  age  class\n",
       "0     6   148    72    35     0  33.6  627.000   50      3\n",
       "1     1    85    66    29     0  26.6  351.000   31      0\n",
       "2     8   183    64     0     0  23.3  672.000   32      1\n",
       "3     1    89    66    23    94  28.1  167.000   21      0\n",
       "4     0   137    40    35   168  43.1    2.288   33      1"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "X=df.drop('class',axis=1)\n",
    "y=df['class']\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "#menghtung jumlah anggota tiap kelas\n",
    "y.value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    500\n",
       "1    267\n",
       "3      1\n",
       "Name: class, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Split dataset into training set and test set\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1) # 70% training and 30% test"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Decision Tree"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "import sklearn.metrics as metrics\n",
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "print( '\\nClassification report\\n' )\n",
    "print(classification_report(y_test, y_pred))\n",
    "print( '\\nConfusion Matrix\\n' )\n",
    "print(confusion_matrix(y_test, y_pred),'\\n')\n",
    "print('Accuracy :','{:.2f}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('F-Score :','{:.2f}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=1)\n",
    "print('AUC:','{:.2f}'.format(metrics.auc(fpr, tpr)))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Classification report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.79      0.76        99\n",
      "           1       0.56      0.50      0.53        54\n",
      "           3       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.68       154\n",
      "   macro avg       0.43      0.43      0.43       154\n",
      "weighted avg       0.67      0.68      0.67       154\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "[[78 21  0]\n",
      " [27 27  0]\n",
      " [ 1  0  0]] \n",
      "\n",
      "Accuracy : 0.68\n",
      "F-Score : 0.67\n",
      "AUC: 0.65\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/jackshaw/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jackshaw/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jackshaw/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# KNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# NB"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb=GaussianNB()\n",
    "# Train Decision Tree Classifer\n",
    "nb= nb.fit(X_train,y_train)\n",
    "#Predict the response for test dataset\n",
    "y_pred= nb.predict(X_test)\n",
    "print( '\\nClassification report\\n' )\n",
    "print(classification_report(y_test, y_pred))\n",
    "print( '\\nConfusion Matrix\\n' )\n",
    "print(confusion_matrix(y_test, y_pred),'\\n')\n",
    "print('Accuracy :','{:.2f}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('F-Score :','{:.2f}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=1)\n",
    "print('AUC:','{:.2f}'.format(metrics.auc(fpr, tpr)))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Classification report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82        99\n",
      "           1       0.66      0.57      0.61        54\n",
      "           3       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.48      0.47      0.48       154\n",
      "weighted avg       0.74      0.75      0.74       154\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "[[84 15  0]\n",
      " [23 31  0]\n",
      " [ 0  1  0]] \n",
      "\n",
      "Accuracy : 0.75\n",
      "F-Score : 0.74\n",
      "AUC: 0.71\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/jackshaw/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jackshaw/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jackshaw/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SVM"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "from sklearn.svm import SVC\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "c_SVC = np.logspace(start = 0, stop = 10, num = 100, base = 2 , dtype = 'float64')\n",
    "param_grid_S = {'C': c_SVC}\n",
    "clf_SVC = SVC(C=100.0, kernel='linear', degree=3, gamma='auto', coef0=0.0, shrinking=True, \n",
    "          probability=False, tol=0.001, cache_size=200, class_weight=None, \n",
    "          verbose=0, max_iter=-1, decision_function_shape=\"ovr\", random_state = 0)\n",
    "svc=clf_SVC.fit(X_train,y_train)\n",
    "y_pred= svc.predict(X_test)\n",
    "print( '\\nClassification report\\n' )\n",
    "print(classification_report(y_test, y_pred))\n",
    "print( '\\nConfusion Matrix\\n' )\n",
    "print(confusion_matrix(y_test, y_pred),'\\n')\n",
    "print('Accuracy :','{:.2f}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('F-Score :','{:.2f}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=1)\n",
    "print('AUC:','{:.2f}'.format(metrics.auc(fpr, tpr)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Classification report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.83        99\n",
      "           1       0.67      0.65      0.66        54\n",
      "           3       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.50      0.50      0.50       154\n",
      "weighted avg       0.76      0.77      0.76       154\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "[[83 16  0]\n",
      " [19 35  0]\n",
      " [ 0  1  0]] \n",
      "\n",
      "Accuracy : 0.77\n",
      "F-Score : 0.76\n",
      "AUC: 0.74\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random Forest"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf= RandomForestClassifier (n_estimators=100,random_state=0)\n",
    "rf= rf.fit(X_train, y_train)\n",
    "y_pred= rf.predict(X_test)\n",
    "print( '\\nClassification report\\n' )\n",
    "print(classification_report(y_test, y_pred))\n",
    "print( '\\nConfusion Matrix\\n' )\n",
    "print(confusion_matrix(y_test, y_pred),'\\n')\n",
    "print('Accuracy :','{:.2f}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('F-Score :','{:.2f}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=1)\n",
    "print('AUC:','{:.2f}'.format(metrics.auc(fpr, tpr)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Classification report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.83        99\n",
      "           1       0.69      0.69      0.69        54\n",
      "           3       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.78       154\n",
      "   macro avg       0.51      0.51      0.51       154\n",
      "weighted avg       0.77      0.78      0.78       154\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "[[83 16  0]\n",
      " [17 37  0]\n",
      " [ 0  1  0]] \n",
      "\n",
      "Accuracy : 0.78\n",
      "F-Score : 0.78\n",
      "AUC: 0.76\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Regresi Logistic"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "rf = LogisticRegression(random_state=0)\n",
    "rf= rf.fit(X_train, y_train)\n",
    "y_pred= rf.predict(X_test)\n",
    "print( '\\nClassification report\\n' )\n",
    "print(classification_report(y_test, y_pred))\n",
    "print( '\\nConfusion Matrix\\n' )\n",
    "print(confusion_matrix(y_test, y_pred),'\\n')\n",
    "print('Accuracy :','{:.2f}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('F-Score :','{:.2f}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=1)\n",
    "print('AUC:','{:.2f}'.format(metrics.auc(fpr, tpr)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Classification report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.88      0.77        99\n",
      "           1       0.56      0.28      0.37        54\n",
      "           3       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.66       154\n",
      "   macro avg       0.41      0.39      0.38       154\n",
      "weighted avg       0.64      0.66      0.62       154\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "[[87 12  0]\n",
      " [39 15  0]\n",
      " [ 1  0  0]] \n",
      "\n",
      "Accuracy : 0.66\n",
      "F-Score : 0.62\n",
      "AUC: 0.58\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}